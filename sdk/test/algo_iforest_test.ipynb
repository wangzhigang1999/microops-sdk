{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-25 19:57:56.204 | INFO     | sdk.base:__inference:116 - ..............Starting inference..............\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 64>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     59\u001B[0m         \u001B[38;5;28mprint\u001B[39m(result)\n\u001B[1;32m     60\u001B[0m         \u001B[38;5;66;03m# return result\u001B[39;00m\n\u001B[0;32m---> 64\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mIsolationForest\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/sdk/sdk/base.py:35\u001B[0m, in \u001B[0;36mAlgoTemplate.__init__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mmodel_storage\u001B[38;5;241m.\u001B[39mload_model(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mmodel_path)\n\u001B[0;32m---> 35\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__inference\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/sdk/sdk/base.py:117\u001B[0m, in \u001B[0;36mAlgoTemplate.__inference\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__inference\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    116\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m..............Starting inference..............\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m message \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39minference_datasource\u001B[38;5;241m.\u001B[39mget_stream_handler():\n\u001B[1;32m    118\u001B[0m         message_value \u001B[38;5;241m=\u001B[39m message\u001B[38;5;241m.\u001B[39mvalue\n\u001B[1;32m    119\u001B[0m         message_value[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mfloat\u001B[39m(message_value[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/sockshop_env/lib/python3.9/site-packages/kafka/consumer/group.py:1193\u001B[0m, in \u001B[0;36mKafkaConsumer.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1191\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnext_v1()\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1193\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext_v2\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/sockshop_env/lib/python3.9/site-packages/kafka/consumer/group.py:1201\u001B[0m, in \u001B[0;36mKafkaConsumer.next_v2\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1199\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message_generator_v2()\n\u001B[1;32m   1200\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1201\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_iterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1202\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m:\n\u001B[1;32m   1203\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/sockshop_env/lib/python3.9/site-packages/kafka/consumer/group.py:1116\u001B[0m, in \u001B[0;36mKafkaConsumer._message_generator_v2\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_message_generator_v2\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m   1115\u001B[0m     timeout_ms \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1000\u001B[39m \u001B[38;5;241m*\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_consumer_timeout \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mtime())\n\u001B[0;32m-> 1116\u001B[0m     record_map \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout_ms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupdate_offsets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   1117\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m tp, records \u001B[38;5;129;01min\u001B[39;00m six\u001B[38;5;241m.\u001B[39miteritems(record_map):\n\u001B[1;32m   1118\u001B[0m         \u001B[38;5;66;03m# Generators are stateful, and it is possible that the tp / records\u001B[39;00m\n\u001B[1;32m   1119\u001B[0m         \u001B[38;5;66;03m# here may become stale during iteration -- i.e., we seek to a\u001B[39;00m\n\u001B[1;32m   1120\u001B[0m         \u001B[38;5;66;03m# different offset, pause consumption, or lose assignment.\u001B[39;00m\n\u001B[1;32m   1121\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m record \u001B[38;5;129;01min\u001B[39;00m records:\n\u001B[1;32m   1122\u001B[0m             \u001B[38;5;66;03m# is_fetchable(tp) should handle assignment changes and offset\u001B[39;00m\n\u001B[1;32m   1123\u001B[0m             \u001B[38;5;66;03m# resets; for all other changes (e.g., seeks) we'll rely on the\u001B[39;00m\n\u001B[1;32m   1124\u001B[0m             \u001B[38;5;66;03m# outer function destroying the existing iterator/generator\u001B[39;00m\n\u001B[1;32m   1125\u001B[0m             \u001B[38;5;66;03m# via self._iterator = None\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/sockshop_env/lib/python3.9/site-packages/kafka/consumer/group.py:655\u001B[0m, in \u001B[0;36mKafkaConsumer.poll\u001B[0;34m(self, timeout_ms, max_records, update_offsets)\u001B[0m\n\u001B[1;32m    653\u001B[0m remaining \u001B[38;5;241m=\u001B[39m timeout_ms\n\u001B[1;32m    654\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 655\u001B[0m     records \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll_once\u001B[49m\u001B[43m(\u001B[49m\u001B[43mremaining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_records\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mupdate_offsets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mupdate_offsets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    656\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m records:\n\u001B[1;32m    657\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m records\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/sockshop_env/lib/python3.9/site-packages/kafka/consumer/group.py:702\u001B[0m, in \u001B[0;36mKafkaConsumer._poll_once\u001B[0;34m(self, timeout_ms, max_records, update_offsets)\u001B[0m\n\u001B[1;32m    699\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client\u001B[38;5;241m.\u001B[39mpoll(timeout_ms\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    701\u001B[0m timeout_ms \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(timeout_ms, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_coordinator\u001B[38;5;241m.\u001B[39mtime_to_next_poll() \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m)\n\u001B[0;32m--> 702\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout_ms\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;66;03m# after the long poll, we should check whether the group needs to rebalance\u001B[39;00m\n\u001B[1;32m    704\u001B[0m \u001B[38;5;66;03m# prior to returning data so that the group can stabilize faster\u001B[39;00m\n\u001B[1;32m    705\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_coordinator\u001B[38;5;241m.\u001B[39mneed_rejoin():\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/sockshop_env/lib/python3.9/site-packages/kafka/client_async.py:602\u001B[0m, in \u001B[0;36mKafkaClient.poll\u001B[0;34m(self, timeout_ms, future)\u001B[0m\n\u001B[1;32m    599\u001B[0m             timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(timeout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mretry_backoff_ms\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m    600\u001B[0m         timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m0\u001B[39m, timeout)  \u001B[38;5;66;03m# avoid negative timeouts\u001B[39;00m\n\u001B[0;32m--> 602\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    604\u001B[0m \u001B[38;5;66;03m# called without the lock to avoid deadlock potential\u001B[39;00m\n\u001B[1;32m    605\u001B[0m \u001B[38;5;66;03m# if handlers need to acquire locks\u001B[39;00m\n\u001B[1;32m    606\u001B[0m responses\u001B[38;5;241m.\u001B[39mextend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fire_pending_completed_requests())\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/sockshop_env/lib/python3.9/site-packages/kafka/client_async.py:634\u001B[0m, in \u001B[0;36mKafkaClient._poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_register_send_sockets()\n\u001B[1;32m    633\u001B[0m start_select \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m--> 634\u001B[0m ready \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    635\u001B[0m end_select \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m    636\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sensors:\n",
      "File \u001B[0;32m~/opt/miniconda3/envs/sockshop_env/lib/python3.9/selectors.py:562\u001B[0m, in \u001B[0;36mKqueueSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    560\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    561\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 562\u001B[0m     kev_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontrol\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_ev\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    563\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[1;32m    564\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from pyod.models.iforest import IForest\n",
    "import pandas as pd\n",
    "\n",
    "from sdk.base import AlgoTemplate\n",
    "\n",
    "# 为config设置环境变量\n",
    "# config_file_path = \"../config/example/config-iforest-train-example.json\"\n",
    "config_file_path = \"../config/example/config-iforest-inference-example.json\"\n",
    "with open(config_file_path) as config_file:\n",
    "    config_content = config_file.read()\n",
    "# print(\"config_content: {}\".format(config_content))\n",
    "# os.environ[\"MODE\"] = \"TRAIN\"\n",
    "os.environ[\"MODE\"] = \"INFERENCE\"\n",
    "\n",
    "os.environ[\"CONFIG\"] = config_content\n",
    "\n",
    "class IsolationForest(AlgoTemplate):\n",
    "\n",
    "    def build_model(self, hyper_params: dict) -> object:\n",
    "        model = IForest(verbose=hyper_params[\"verbose\"])\n",
    "        return model\n",
    "\n",
    "    def train(self, model: object, df: pd.DataFrame, hyper_params: dict) -> (object, dict):\n",
    "        # preprocess\n",
    "        print(\"check null: {}\".format(df.isnull().values.any()))\n",
    "        print(\"df max: {} min:{}\".format(df.max(), df.min()))\n",
    "        min_max = df.apply(lambda x: pd.Series([x.min(), x.max()])).T.values.tolist()\n",
    "        for i, col in enumerate(df):\n",
    "            df[col] = (df[col] - min_max[i][0]) / (min_max[i][1] - min_max[i][0])\n",
    "        print(\"train df after normalization : {}\".format(df))\n",
    "\n",
    "        # train\n",
    "        x_train = df.to_numpy()\n",
    "        model.fit(x_train)\n",
    "        y_train_pred = model.labels_  # binary labels (0: inliers, 1: outliers)\n",
    "        y_train_scores = model.decision_scores_  # raw outlier scores\n",
    "        print(y_train_pred)\n",
    "        print(y_train_scores)\n",
    "        return model, {\"min_max\": min_max}\n",
    "\n",
    "    def inference(self, model: object, args: dict, df: pd.DataFrame) -> pd.Series:\n",
    "        # preprocess\n",
    "        min_max = args[\"min_max\"]\n",
    "        print(\"min max for inference: {}\".format(min_max))\n",
    "        for i, col in enumerate(df):\n",
    "            df[col] = (df[col] - min_max[i][0]) / (min_max[i][1] - min_max[i][0])\n",
    "        print(\"inference df after normalization: {}\".format(df))\n",
    "        #inference\n",
    "        x_test = df.to_numpy()\n",
    "        y_test_pred = model.predict(x_test)\n",
    "        y_test_scores = model.decision_function(x_test)\n",
    "        print(y_test_pred)\n",
    "        print(y_test_scores)\n",
    "\n",
    "        result = pd.Series(y_test_pred)\n",
    "        result.index = df.index\n",
    "        print(result)\n",
    "        # return result\n",
    "\n",
    "\n",
    "\n",
    "model = IsolationForest()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}