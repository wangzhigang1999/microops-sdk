{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "加载config example"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 21:22:28.685 | INFO     | __main__:<cell line: 7>:7 - config file is : ../config-inference-example.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyperParams': {'batch_size': 32, 'epochs': 10}, 'modelPath': 'testModelPath', 'resultPath': 'result', 'trainJobName': 'nginx-pure-data-ecl-64778820', 'datasetStartTime': -1, 'ckptName': 'nginx-pure_data.ECL-64778820', 'storage': [{'type': 'REDIS', 'usage': 'model', 'host': 'localhost', 'port': 6379, 'password': '', 'properties': {'db': 0}}, {'type': 'MONGODB', 'usage': 'result', 'host': '10.112.169.94', 'port': 30332, 'username': 'root', 'password': 'root', 'properties': {'db': 'evaluation'}}], 'selectedFields': ['MT_000', 'MT_001', 'date'], 'algorithm': {'type': 'KNN', 'name': 'nginx', 'description': 'nginx', 'author': 'wanz', 'version': '1.0', 'url': 'nginx', 'hyperParameters': {'hello': 'world'}, 'command': ' ', 'hashString': '104760218104760218364187848563104760218197974952332', 'id': '63f320a11a1cf03bbd8f01c6'}, 'datasetEndTime': -1, 'dataSource': {'type': 'KAFKA', 'host': '192.168.31.197', 'port': 9092, 'username': 'root', 'password': 'root', 'properties': {'topic': 'node_metrics', 'groupID': 'anomaly_detection'}}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from loguru import logger\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "训练和推理的datasource不同，因此\n",
    "测试训练的config需要在config中修改mode = \"TRAIN\"， 并在下方选择config-train-example.json\n",
    "测试推理的config需要在config中修改mode = \"INFERENCE\"，并在下方选择config-inference-example.json\n",
    "'''\n",
    "# config_file_path = \"../config-train-example.json\"\n",
    "config_file_path = \"../config-inference-example.json\"\n",
    "logger.info(\"config file is : {}\".format(config_file_path))\n",
    "\n",
    "with open(config_file_path) as config_file:\n",
    "    config_content = config_file.read()\n",
    "\n",
    "json_config = json.loads(config_content)\n",
    "print(json_config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "测试config基本字段"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-24 21:22:28.768 | INFO     | sdk.config.config:__init__:21 - current mode is INFERENCE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected fields: ['MT_000', 'MT_001', 'date']\n",
      "algorithm name: nginx\n"
     ]
    }
   ],
   "source": [
    "from sdk.config.config import Config\n",
    "\n",
    "config = Config(json_config)\n",
    "print(\"selected fields: {}\".format(config.selected_fields))\n",
    "print(\"algorithm name: {}\".format(config.algorithm.get_name()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "测试storage"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'min': 1, 'max': 2}\n"
     ]
    }
   ],
   "source": [
    "# model storage and redis storage\n",
    "model_storage = config.get_model_storage()\n",
    "\n",
    "\n",
    "class TestModel:\n",
    "    def __init__(self):\n",
    "        self.data = 1\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.data\n",
    "\n",
    "\n",
    "model = TestModel()\n",
    "\n",
    "model_storage.save_model(config.model_path, model, {\"min\": 1, \"max\": 2})\n",
    "model_retrieve, args = model_storage.load_model(config.model_path)\n",
    "print(model_retrieve.get_data())\n",
    "print(args)\n",
    "\n",
    "# result storage and mongo storage\n",
    "result_storage = config.get_result_storage()\n",
    "result_storage.store_result(config.result_path, \"test-algo\", [\"test-metric1\"], [\"test-target1\"], pd.Series([\"1\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "测试datasource"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cmdb_id': 'k8s-large-1665988619', 'name': 'node_filefd_allocated', 'timestamp': '2023-02-24T13:22:37Z', 'value': '8288'}\n",
      "{'cmdb_id': 'k8s-large-1665988619', 'name': 'node_load1', 'timestamp': '2023-02-24T13:22:37Z', 'value': '0.36'}\n",
      "{'cmdb_id': 'k8s-large-1665988619', 'name': 'node_load15', 'timestamp': '2023-02-24T13:22:37Z', 'value': '0.37'}\n",
      "{'cmdb_id': 'k8s-large-1665988619', 'name': 'node_load5', 'timestamp': '2023-02-24T13:22:37Z', 'value': '0.43'}\n",
      "{'cmdb_id': 'k8s-large-1665988619', 'name': 'node_memory_Active_anon_bytes', 'timestamp': '2023-02-24T13:22:37Z', 'value': '6368419840'}\n"
     ]
    }
   ],
   "source": [
    "# train datasource and mongo datasource\n",
    "if \"train\" in config_file_path:\n",
    "    train_datasource = config.get_train_datasource()\n",
    "    train_datasource.set_default_projected_fields({\"_id\": 0})\n",
    "    train_datasource.set_default_df_index(\"date\")\n",
    "    data = train_datasource.get_data(config.dataset_start_time, config.dataset_end_time, config.selected_fields)\n",
    "\n",
    "# inference datasource and kafka datasource\n",
    "elif \"inference\" in config_file_path:\n",
    "    inference_datasource = config.get_inference_datasource()\n",
    "    stream = inference_datasource.get_stream_handler()\n",
    "\n",
    "    count = 0\n",
    "    for message in stream:\n",
    "        mvalue = message.value\n",
    "        print(mvalue)\n",
    "        count += 1\n",
    "        if count == 5:\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}